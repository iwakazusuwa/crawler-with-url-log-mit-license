# crawler-with-url-log-mit-license

指定した検索ワードで Bing から画像をスクレイピングし、画像 URL 一覧を作成する Python スクリプトです。`icrawler` ライブラリを活用し、取得した画像と対応 URL を CSV に記録し、画像はキーワードごとに整理したフォルダに保存します。

---

## 概要

- 複数キーワードに対応し、キーワードごとに画像をフォルダ分け
- 画像保存時に取得元 URL を CSV に自動記録
- 画像は縦 100 ピクセルにリサイズし Excel に貼り付け
- 画像 URL はハイパーリンク付きで管理可能

---

## フォルダ構成

```
├─ crawler_url.py          # 画像検索、ダウンロード、CSV作成、Excel作成を一括で実行するスクリプト
├─ LICENSE.txt             # ライセンスファイル（MITライセンス）
├─ README.md               # 本ドキュメント
└─ image_YYYYMMDDHHMMSS/   # 実行時に作成される保存フォルダ（日時で自動命名）
    ├─ リスト.csv          # ダウンロードした画像のファイル名とURL一覧を記録したCSVファイル
    └─ output.xlsx         # 画像と情報を貼り付けたExcelファイル

```


## 特徴

- 複数キーワードに対応し、キーワードごとに画像をフォルダ分け
- 画像保存時に取得元 URL を CSV に自動記録
- 画像は縦 100 ピクセルにリサイズし Excel に貼り付け
- 画像 URL はハイパーリンク付きで管理可能

---

## 必要なパッケージ

以下のパッケージが必要です。`requirements.txt` を使用してインストールできます。

```bash
pip install -r requirements.txt
```
---
# 使い方

1. crawler_url.py を実行します。
```
python crawler_url.py
```

2. 実行後、image_YYYYMMDDHHMMSS/ フォルダが作成され、その中に画像と情報が保存されます。

---
# 貢献方法
プロジェクトへの貢献は以下の方法で歓迎します：
- バグ報告や機能追加の提案は Issues で
- コード改善や新機能追加は Pull Request で
- ドキュメント改善や翻訳も歓迎

---
# 注意事項
- 取得した画像の著作権・利用権は各自でご確認ください。
- 大量の取得はサーバーに負荷をかけるため適切な枚数設定を推奨。
- Windows環境での動作を想定しています。
- 本プログラムは画像の自動収集を目的としており、ウェブサイトのコンテンツをスクレイピングしています。
- しかし、サイトごとにスクレイピングや画像の自動取得を禁止している場合があります。
- ご利用の際は、対象サイトの利用規約やrobots.txtなどを必ずご確認のうえ、許可されている範囲内でご利用ください。
- 過剰なアクセスや大量ダウンロードは、サーバーに負荷をかけるため避けてください。
- 著作権や肖像権など、取得した画像の権利関係にも十分注意してください。
- 万が一問題が発生した場合でも、本リポジトリ及び作成者は一切の責任を負いかねます。自己責任での利用をお願いいたします。

---
# ライセンス
MIT License（詳細は LICENSE ファイル参照）

#### 開発者： iwakazusuwa(Swatchp)
