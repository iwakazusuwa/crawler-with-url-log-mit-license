

#ler-with-url-log-mit-license
指定された検索ワードの画像をスクレイピングしながら画像URL一覧ファイル作成します。

## 概要
- Pythonのicrawlerを活用し、指定した複数キーワードでBingから画像を自動取得
- 取得した画像と対応URLをCSVに記録し、画像はキーワードごとに整理したフォルダに保存
- 画像をリサイズしてExcelに貼り付け、URLはハイパーリンク付きで管理可能

## ファイル構成

```
├─ crawler_url.py          # 画像検索、ダウンロード、CSV作成、Excel作成を一括で実行するスクリプト
├─ LICENSE.txt             # ライセンスファイル（MITライセンス）
├─ README.md               # 本ドキュメント
└─ image_YYYYMMDDHHMMSS/   # 実行時に作成される保存フォルダ（日時で自動命名）
    ├─ リスト.csv          # ダウンロードした画像のファイル名とURL一覧を記録したCSVファイル
    └─ output.xlsx         # 画像と情報を貼り付けたExcelファイル

```

## 特徴
- 複数キーワードに対応し、キーワードごとに画像をフォルダ分け
- 画像保存時に取得元URLをCSVに自動記録
- 画像は縦100ピクセルにリサイズしExcelに貼り付け
- Excel内で画像・URL・ファイル名・フォルダ名を一覧表示
- Windows環境なら処理後に自動で保存フォルダとExcelを開く

## 環境・依存関係
- Python 3.7以降
- ライブラリ: icrawler, openpyxl, pillow, selenium
- Windows推奨（os.startfile使用のため）

## セットアップ方法
```
pip install icrawler openpyxl pillow selenium
```

## 使い方
このスクリプトは、コマンドライン操作なしで、ファイルをダブルクリックするだけで実行できます。

- スクリプト内の検索キーワードリストと取得枚数を設定
- スクリプトを実行すると画像が自動で取得・整理され、Excelが生成される
- 完了後、保存先フォルダとExcelが自動で開きます


## 注意事項
- 取得した画像の著作権・利用権は各自でご確認ください。
- 大量の取得はサーバーに負荷をかけるため適切な枚数設定を推奨。
- Windows環境での動作を想定しています。
- 本プログラムは画像の自動収集を目的としており、ウェブサイトのコンテンツをスクレイピングしています。
- しかし、サイトごとにスクレイピングや画像の自動取得を禁止している場合があります。
- ご利用の際は、対象サイトの利用規約やrobots.txtなどを必ずご確認のうえ、許可されている範囲内でご利用ください。
- 過剰なアクセスや大量ダウンロードは、サーバーに負荷をかけるため避けてください。
- 著作権や肖像権など、取得した画像の権利関係にも十分注意してください。
- 万が一問題が発生した場合でも、本リポジトリ及び作成者は一切の責任を負いかねます。自己責任での利用をお願いいたします。


## ライセンス
MIT License

#### 開発者： iwakazusuwa(Swatchp)
